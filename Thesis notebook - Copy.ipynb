{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b78da68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Libraries\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import cifar10\n",
    "from keras import backend as K\n",
    "import cv2\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "# Custom Networks\n",
    "from networks.lenet import LeNet\n",
    "from networks.resnet import ResNet\n",
    "from networks.pure_cnn import PureCnn\n",
    "from networks.network_in_network import NetworkInNetwork\n",
    "from networks.densenet import DenseNet\n",
    "from networks.wide_resnet import WideResNet\n",
    "from networks.capsnet import CapsNet\n",
    "\n",
    "# Helper functions\n",
    "from differential_evolution import differential_evolution\n",
    "import helper\n",
    "\n",
    "matplotlib.style.use('ggplot')\n",
    "np.random.seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3105d363",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d090643f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded lenet\n",
      "Successfully loaded resnet\n"
     ]
    }
   ],
   "source": [
    "# Custom Networks\n",
    "from networks.lenet import LeNet\n",
    "from networks.resnet import ResNet\n",
    "\n",
    "lenet = LeNet()\n",
    "resnet = ResNet()\n",
    "\n",
    "models = [lenet, resnet]\n",
    "\n",
    "# Uncomment below to load more models to play with. Make sure the model files exist by training or downloading them.\n",
    "\n",
    "# lenet = LeNet()\n",
    "# pure_cnn = PureCnn()\n",
    "# net_in_net = NetworkInNetwork()\n",
    "# resnet = ResNet()\n",
    "# densenet = DenseNet()\n",
    "# wide_resnet = WideResNet()\n",
    "# capsnet = CapsNet()\n",
    "\n",
    "# models = [lenet, pure_cnn, net_in_net, resnet, densenet, wide_resnet, capsnet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7888d7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating lenet\n",
      "79/79 [==============================] - 0s 2ms/step\n",
      "Evaluating resnet\n",
      "79/79 [==============================] - 4s 39ms/step\n",
      "Index(['name', 'accuracy', 'param_count'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>param_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lenet</td>\n",
       "      <td>0.7488</td>\n",
       "      <td>62006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>resnet</td>\n",
       "      <td>0.9231</td>\n",
       "      <td>470218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name  accuracy  param_count\n",
       "0   lenet    0.7488        62006\n",
       "1  resnet    0.9231       470218"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_stats, correct_imgs = helper.evaluate_models(models, x_test, y_test)\n",
    "correct_imgs = pd.DataFrame(correct_imgs, columns=['name', 'img', 'label', 'confidence', 'pred'])\n",
    "network_stats = pd.DataFrame(network_stats, columns=['name', 'accuracy', 'param_count'])\n",
    "print(network_stats.columns)\n",
    "\n",
    "network_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f4a99a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturb_image(xs, img, sigma=0.7):\n",
    "    # If this function is passed just one perturbation vector,\n",
    "    # pack it in a list to keep the computation the same\n",
    "    if xs.ndim < 2:\n",
    "        xs = np.array([xs])\n",
    "\n",
    "    # Copy the image n == len(xs) times so that we can\n",
    "    # create n new perturbed images\n",
    "    tile = [len(xs)] + [1] * (xs.ndim + 1)\n",
    "    imgs = np.tile(img, tile)\n",
    "\n",
    "    # Make sure to floor the members of xs as int types\n",
    "    xs = xs.astype(int)\n",
    "\n",
    "    # Initialize an empty array to store the coordinates of the optimized pixels\n",
    "    optimized_pixels = np.zeros((len(xs), xs.shape[1] // 5, 2), dtype=int)\n",
    "\n",
    "    for i, (x, img) in enumerate(zip(xs, imgs)):\n",
    "        # Split x into an array of 5-tuples (perturbation pixels)\n",
    "        # i.e., [[x,y,r,g,b], ...]\n",
    "        pixels = np.split(x, len(x) // 5)\n",
    "        for j, pixel in enumerate(pixels):\n",
    "            # At each pixel's x,y position, assign its rgb value\n",
    "            x_pos, y_pos, *rgb = pixel\n",
    "            img[x_pos, y_pos] = rgb\n",
    "            # Store the coordinates of the optimized pixels\n",
    "            optimized_pixels[i, j] = [x_pos, y_pos]\n",
    "\n",
    "            # Apply a Gaussian filter around the perturbed pixel\n",
    "            # The filter size is determined by the sigma value\n",
    "#             x_min = max(0, x_pos - int(sigma * 1.5))\n",
    "#             x_max = min(img.shape[0], x_pos + int(sigma * 1.5) + 1)\n",
    "#             y_min = max(0, y_pos - int(sigma * 1.5))\n",
    "#             y_max = min(img.shape[1], y_pos + int(sigma * 1.5) + 1)\n",
    "            \n",
    "            x_min = max(0, x_pos - int(sigma * 3))\n",
    "            x_max = min(img.shape[0], x_pos + int(sigma * 3) + 1)\n",
    "            y_min = max(0, y_pos - int(sigma * 3))\n",
    "            y_max = min(img.shape[1], y_pos + int(sigma * 3) + 1)\n",
    "\n",
    "            img[x_min:x_max, y_min:y_max] = gaussian_filter(img[x_min:x_max, y_min:y_max], sigma=sigma)\n",
    "\n",
    "    return imgs, optimized_pixels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dd34e962",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_classes(xs, img, target_class, model, minimize=True):\n",
    "    # Perturb the image with the given pixel(s) x and get the prediction of the model\n",
    "    imgs_perturbed = perturb_image(xs, img)\n",
    "    predictions = model.predict(imgs_perturbed[0])[:,target_class]\n",
    "    # This function should always be minimized, so return its complement if needed\n",
    "    return predictions if minimize else 1 - predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "872b8c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack_success(x, img, target_class, model, targeted_attack=False, verbose=False):\n",
    "    # Perturb the image with the given pixel(s) and get the prediction of the model\n",
    "    attack_image = perturb_image(x, img)\n",
    "\n",
    "    confidence = model.predict(attack_image[0])[0]\n",
    "    predicted_class = np.argmax(confidence)\n",
    "    \n",
    "    # If the prediction is what we want (misclassification or \n",
    "    # targeted classification), return True\n",
    "    if verbose:\n",
    "        print('Confidence:', confidence[target_class])\n",
    "    if ((targeted_attack and predicted_class == target_class) or\n",
    "        (not targeted_attack and predicted_class != target_class)):\n",
    "        return True\n",
    "    # NOTE: return None otherwise (not False), due to how Scipy handles its callback function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "91f74f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_color_neighborhood(img, x, y, neighborhood_size=1):\n",
    "    x_min = max(0, x - neighborhood_size)\n",
    "    x_max = min(img.shape[0], x + neighborhood_size + 1)\n",
    "    y_min = max(0, y - neighborhood_size)\n",
    "    y_max = min(img.shape[1], y + neighborhood_size + 1)\n",
    "\n",
    "    neighborhood = img[x_min:x_max, y_min:y_max]\n",
    "    return np.mean(neighborhood, axis=(0, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9b95054c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack(img_id, model, target=None, pixel_count=1, \n",
    "           maxiter=75, popsize=400, verbose=False):\n",
    "    # Change the target class based on whether this is a targeted attack or not\n",
    "    targeted_attack = target is not None\n",
    "    target_class = target if targeted_attack else y_test[img_id, 0]\n",
    "    \n",
    "    bounds = []\n",
    "    neighborhood_size = 1  # Define the size of the neighborhood (1 means directly neighboring pixels)\n",
    "    for _ in range(pixel_count):\n",
    "        bounds.extend([(0, 32), (0, 32)])\n",
    "        x, y = np.random.randint(0, 32, size=2)  # Randomly choose a pixel location\n",
    "        avg_color = average_color_neighborhood(x_test[img_id], x, y, neighborhood_size)\n",
    "        color_bounds = [(max(0, color - 10), min(255, color + 10)) for color in avg_color]  # Adjust color range here\n",
    "        bounds.extend(color_bounds)\n",
    "    \n",
    "    \n",
    "    # Population multiplier, in terms of the size of the perturbation vector x\n",
    "    popmul = max(1, popsize // len(bounds))\n",
    "    \n",
    "    # Format the predict/callback functions for the differential evolution algorithm\n",
    "    def predict_fn(xs):\n",
    "        return predict_classes(xs, x_test[img_id], target_class, \n",
    "                               model, target is None)\n",
    "    \n",
    "    def callback_fn(x, convergence):\n",
    "        return attack_success(x, x_test[img_id], target_class, \n",
    "                              model, targeted_attack, verbose)\n",
    "    \n",
    "    # Call Scipy's Implementation of Differential Evolution\n",
    "    attack_result = differential_evolution(\n",
    "        predict_fn, bounds, maxiter=maxiter, popsize=popmul,\n",
    "        recombination=1, atol=-1, callback=callback_fn, polish=False)\n",
    "\n",
    "    # Calculate some useful statistics to return from this function\n",
    "    attack_image = perturb_image(attack_result.x, x_test[img_id])[0]\n",
    "    attack_image_smoothed = gaussian_filter(attack_image, sigma=0.1)\n",
    "    prior_probs = model.predict_one(x_test[img_id])\n",
    "    predicted_probs = model.predict_one(attack_image)\n",
    "    predicted_class = np.argmax(predicted_probs)\n",
    "    actual_class = y_test[img_id, 0]\n",
    "    success = predicted_class != actual_class\n",
    "    cdiff = prior_probs[actual_class] - predicted_probs[actual_class]\n",
    "\n",
    "    perturb_pixels = perturb_image(attack_result.x, x_test[img_id])[1]\n",
    "    \n",
    "    helper.plot_image(attack_image_smoothed, actual_class, class_names, predicted_class)\n",
    "    \n",
    "    return [model.name, pixel_count, img_id, actual_class, predicted_class,\n",
    "            success, cdiff, prior_probs, predicted_probs, attack_result.x, attack_image_smoothed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3da0b7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Confidence: 0.09369888\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# No: 1, 3: Calculate the confidence values\n",
    "# Yes: 118, 169, 2978, 658, 1001, 1116\n",
    "# 1, 2, 3, 4, 5, 7, 10, 15, 20\n",
    "\n",
    "image_id = 1297\n",
    "pixels = 1 # Number of pixels to attack\n",
    "model = lenet\n",
    "\n",
    "_ = attack(image_id, model, pixel_count=pixels, verbose=True)\n",
    "\n",
    "attack_image = _[10]\n",
    "attack_image = np.reshape(attack_image, (32, 32, 3))\n",
    "\n",
    "plt.imshow(attack_image-x_test[image_id])\n",
    "# plt.imshow(x_test[image_id])\n",
    "plt.gca().set_axis_off()\n",
    "plt.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463f62ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def attack_all(models, samples=500, pixels=(1,5,10,20), targeted=False, \n",
    "#                maxiter=75, popsize=400, verbose=False):\n",
    "#     results = []\n",
    "#     for model in models:\n",
    "#         model_results = []\n",
    "#         valid_imgs = correct_imgs[correct_imgs.name == model.name].img\n",
    "#         img_samples = np.random.choice(valid_imgs, samples, replace=False)\n",
    "        \n",
    "#         for pixel_count in pixels:\n",
    "#             for i, img_id in enumerate(img_samples):\n",
    "#                 print('\\n', model.name, '- image', img_id, '-', i+1, '/', len(img_samples))\n",
    "#                 targets = [None] if not targeted else range(10)\n",
    "                \n",
    "#                 for target in targets:\n",
    "#                     if targeted:\n",
    "#                         print('Attacking with target', class_names[target])\n",
    "#                         if target == y_test[img_id, 0]:\n",
    "#                             continue\n",
    "#                     result = attack(img_id, model, target, pixel_count, \n",
    "#                                     maxiter=maxiter, popsize=popsize, \n",
    "#                                     verbose=verbose)\n",
    "#                     model_results.append(result)\n",
    "                    \n",
    "#         results += model_results\n",
    "#         helper.checkpoint(results, targeted)\n",
    "#     return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b55999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# untargeted = attack_all(models, samples=90, targeted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1dc01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Find the number of columns in the first row of the data\n",
    "# num_columns = len(untargeted[0])\n",
    "\n",
    "# # Create a list of column names\n",
    "# columns = ['model', 'pixels', 'image', 'true', 'predicted', 'success', 'cdiff', 'prior_probs', 'predicted_probs', 'perturbation']\n",
    "\n",
    "# # If the number of columns in the data is greater than the length of the `columns` list, add 'extra_column_i' for each extra column\n",
    "# for i in range(len(columns), num_columns):\n",
    "#     columns.append(f'extra_column_{i}')\n",
    "\n",
    "# # Create the DataFrame with the updated `columns` list\n",
    "# untargeted_results = pd.DataFrame(untargeted, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2201f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper.attack_stats(untargeted_results, models, network_stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
